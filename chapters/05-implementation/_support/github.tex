\subsection{GitHub API}
\label{sec:foundation-github}

Since the project will require every suitable static site source to be hosted on GitHub, the GitHub API is able to provide short and fast overviews of their current state. For providing an automated static site builder, the project needs to rely on some crucial informations before being able to set everything in place.

Because of the fact, that speed and performance are the dominant factors in such considerations, it is unlikely to look up informations from a ``physical'' file tree on the disk, unless it cannot be done using a service, which already delivers data in an understandable form. Hence the GitHub API offers a wide range of informations about a hosted repository and furthermore is able to cope with a constantly high amount of load, it should be a good fit while even having the need of sending multiple requests until receiving the right extent of data.

The most important API calls for this project are listed below, their description may be found on GitHub's API Reference\footnote{\url{https://developer.github.com/v3/} -- API Reference for version 3 on GitHub.}.

\begin{itemize}
  \item \texttt{/repos/:owner/:repo/git/trees/:sha} -- Returns the file tree of a repository at a given commit hash.
  \item \texttt{/repos/:owner/:repo/contents/:path} -- Returns the contents of a file or directory. %% 1MB file limit!
  \item \texttt{/repos/:owner/:repo/:archive\_format/:ref} -- Returns the link for a repo tarball at a given reference (e.g. \emph{master}, but can also be a commit hash).
  \item \texttt{/repos/:owner/:repo/commits} -- Returns commits for the given repository.
  \item \texttt{/repos/:owner/:repo/compare/:base...:head} -- Returns affected files between a \emph{base} and \emph{head} commit. Comparison between branches and/or forked repositories is also possible.
\end{itemize}

\subsubsection{Get a Tree}
One of the most important steps prior to working with a foreign website source is the examination of its file structure, especially when dealing with static site sources. Unlike any other dynamic project, which probably updates itself using certain online sources under predefined circumstances, a static site nearly always has to be rebuilt from scratch.

Although it is also possible to unveil the desired state from the past by reverting to that commit, multiple actions have to be taken before succeeding in that task. This goes from checking out the branch the commit belongs to, triggering a \texttt{git revert} command -- which reverts the changes made up to the current commit \cite{GitRevert} -- to reading in the file tree using any third-party plugin like \emph{node-klaw}\footnote{\url{https://github.com/jprichardson/node-klaw} -- Klaw's repository on GitHub.}.

When calling the ``Get a Tree'' endpoint on the GitHub API although via a GET request, the response contains an array of objects, including file paths, as well as informations whether it is a file or directory (among others). Based on the provided parameters like \emph{recursive}, the endpoint filters every file and directory down to the lowest level, instead of returning only the files living in the top level of the repository. If the response also bears a \emph{truncated} key with value ``true'', the repository exceeded the file limit and not every file could be filtered. In this case, a manual checkout would be necessary\footnote{\url{https://developer.github.com/v3/git/trees/\#get-a-tree} -- ``Get a Tree''-section in the GitHub API Reference.}.

\subsubsection{Get contents}
After having caught a glimpse of the file structure, it is easy to look up certain file names and therefore check for their existence. Also, it allows for failing early in case of any user defined error concerning the availability of certain files before downloading its contents. Whenever the existence of a desired file is assured by having found its position in the file tree, the API is able to send its raw contents upon requesting the ``Get contents'' endpoint together with the appropriate \emph{Accept} header\footnote{\url{https://developer.github.com/v3/repos/contents/\#get-contents} -- ``Get contents''-section in the GitHub API Reference.}.

The use of this endpoint is as simple as valuable, as it lets the project's engine parse single files (e.g. configurations), without being dependent on downloading whole tarballs or zip archives. This completes the fail-early stage, as it not only checks for existence, but also for parseability of crucial files before requesting and processing heavy project archives. On the other hand, it is also necessary for setting up the required build steps, which should enable a parallel workflow, once everything comes into play.

One of the core limitations, which should be considered here, is a maximum file size of 1MB. Whenever a file exceeds this limit, it should be downloaded as a buffer and read in manually afterwards.

\subsubsection{Get archive link}
Once all the preceding checks have passed, one of the heavier tasks may be executed. Since the possible integrity of the project was assumed using the successfully parsed configuration file, the subsequent step would be to download the static site repository, in fact at a certain commit state in the past, probably.

However, this can only be done using GitHub's API, as the ``Get archive link'' endpoint might be one of the very few, which are not available in the Browser version yet. After the endpoint received a request by the client, it produces an archive according to the provided parameters and prepares a download possibility at a URL, which gets included in the response header, together with a ``302 Found'' HTTP status. Either the framework is configured to automatically follow the issued URL, or a second request to the location included in the \emph{Location} header field, becomes necessary. Private repository archives are issued together with a quickly expiring token\footnote{\url{https://developer.github.com/v3/repos/contents/\#get-archive-link} -- ``Get archive link''-section in the GitHub API Reference.}.

After the download succeeded, a final step would be to extract the archive in a project working directory -- therefore, any further command line interaction for this task becomes obsolete.

\subsubsection{List commits on a repository}
For keeping track on a project, git commits contain a lot of information about the project -- however, probably the most important information is the list of affected files since the last commit \cite[65]{loeliger2012version}. Normally, git projects include these snapshots automatically, but since the downloaded archive from the GitHub API does not contain any git-specific files, but only source code immediately belonging to the project, the commits have to be obtained from another source.

Due to the fact, that the project will store build results into the database, there might always be a reference to a previous build process and the commit hash used as state of development progress. This will therefore be a starting point from which to query commits from the GitHub API. The ``List commits on a repository'' endpoint provides all commit informations corresponding to the included parameters in the request, up to a certain amount, before subsequent pagination requests become necessary\footnote{\url{https://developer.github.com/v3/repos/commits/\#list-commits-on-a-repository} -- ``List commits on a repository''-section in the GitHub API Reference.}.

The call to this endpoint especially makes sense, if a certain time frame has to be queried and only timestamps are available, as the call may also include \emph{since} and \emph{until} parameters in ISO 8601 format.

\subsubsection{Compare two commits}
Following the download of the website source repository and its commit data, the affected files of the development progress since the last build are the next task in determining the build extent. Because of the caching approach, this is one of the most critical steps, as the affected files mark the beginning of a list of files which need to be considered for a rebuild task.

One of the biggest advantages of this API endpoint is the fact, that parsing the diff manually may be fully omitted, as the response already contains a JSON including all the necessary data concerning the repository modifications within the given time frame. Again, based on the \emph{Accept} header, a custom response in patch or diff format can also be enforced, if it needs to.

%% TODO: Check, if safely deleted still fits!
After fetching the diff data, the list of affected files only has to be filtered based on the modification type (status) of each included file (modified, added, deleted) and synchronized with the existing file tree. All other files may be safely deleted before the build process starts, unless they are critically needed by the static site generator or share any form of dependency to the files present in the diff.
